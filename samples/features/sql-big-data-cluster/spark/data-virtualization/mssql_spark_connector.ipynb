{
    "metadata": {
        "kernelspec": {
            "name": "pyspark3kernel",
            "display_name": "PySpark3"
        },
        "language_info": {
            "name": "pyspark3",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "python",
                "version": 3
            },
            "pygments_lexer": "python3"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": "# Read and write from Spark to SQL using the MSSQL Spark Connector\r\nA typical big data scenario a key usage pattern is high volume, velocity and variety data processing in Spark followed with batch or streaming writes to SQL for access to LOB applications. These usage patterns greatly benefit from a connector that utilizes key SQL optimizations and provides an efficient write to SQLServer master instance and SQL Server data pool in Big Data Clusters.\r\n\r\nMSSQL Spark connector provides an efficient write SQLServer master instance and SQL Server data pool in Big Data Clusters.\r\n\r\nUsage\r\n----\r\n- Familiar Spark DataSource V1 interface\r\n- Referenced by the name \"mssql\" or fully qualified \"com.microsoft.sqlserver.jdbc.spark\"\r\n- Use from supported Spark language bindings ( Python, Scala, Java, R)\r\n- Optionally pass Bulk Copy parameters \r\n\r\n** Note : The image here may not be visible dues to markdown bug. Please change path here to full path to view the image.\r\n<img src =\r\n\"../data-virtualization/MSSQL_Spark_Connector2.jpg\" style=\"float: center;\" alt=\"drawing\" width=\"900\">\r\n\r\nMore details\r\n-----------\r\n\r\nMSSQL Spark connector, uses [SQL Server Bulk copy APIS](https://docs.microsoft.com/en-us/sql/connect/jdbc/using-bulk-copy-with-the-jdbc-driver?view=sql-server-2017#sqlserverbulkcopyoptions) to implement an efficient write to SQL Server. The connector is based on Spark Data source APIs and provides a familiar JDBC interface for access\r\n\r\nThe Sample\r\n---------\r\n\r\nThe following sample shows MSSQL JDBC Connector for read/write QLServer master instance and SQL Server data pool in Big Data Clusters. The sample is divided into 2 parts. The first part shows read/write to SQL Master instance and Part 2 shows read/write to Data Pools in Big Data Cluster. \r\n\r\nIn the sample we' ll \r\n- Read a file from HDFS and do some basic processing \r\n- In Part 1, we'll write the dataframe to SQL server table and then read the table to a dataframe .\r\n- In Part 2, we'll write the dataframe to SQL Server data pool external table and then read it back to a spark data frame. \r\n\r\nPreReq: \r\n- The sample uses a SQL database named \"MyTestDatabase\". Create this before you run this sample. The database can be created as follows\r\n    ``` sql\r\n    Create DATABASE MyTestDatabase\r\n    GO \r\n    ``` \r\n- Download [AdultCensusIncome.csv]( https://amldockerdatasets.azureedge.net/AdultCensusIncome.csv ) to your local machine.  Create a hdfs folder named spark_data and upload the file there. \r\n- [For CTP2.5] Configure the spark session to use the MSSQL Connector jar. The jar can be found at /jar/spark-mssql-connector-assembly-1.0.0.jar post deployment of Big Data Cluster.\r\n\r\n``` sh\r\n    %%configure -f\r\n    {\"conf\": {\"spark.jars\": \"/jar/spark-mssql-connector-assembly-1.0.0.jar\"}}\r\n```\r\n\r\n\r\n    ",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "# Read CSV into a data frame\r\nIn this step we read the CSV into a data frame and do some basic cleanup steps. \r\n\r\n\r\n",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "#spark = SparkSession.builder.getOrCreate()\r\nsc.setLogLevel(\"INFO\")\r\n\r\n#Read a file and then write it to the SQL table\r\ndatafile = \"/spark_data/AdultCensusIncome.csv\"\r\ndf = spark.read.format('csv').options(header='true', inferSchema='true', ignoreLeadingWhiteSpace='true', ignoreTrailingWhiteSpace='true').load(datafile)\r\ndf.show(5)\r\n\r\n\r\n#Process this data. Very simple data cleanup steps. Replacing \"-\" with \"_\" in column names\r\ncolumns_new = [col.replace(\"-\", \"_\") for col in df.columns]\r\ndf = df.toDF(*columns_new)\r\ndf.show(5)\r\n",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Starting Spark application\n"
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>",
                        "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1561072870175_0001</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"https://40.78.87.105:30443/gateway/default/yarn/proxy/application_1561072870175_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://storage-0-0.storage-0-svc.testbdc.svc.cluster.local:8042/node/containerlogs/container_1561072870175_0001_01_000001/root\">Link</a></td><td>âœ”</td></tr></table>"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "SparkSession available as 'spark'.\n"
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "+---+----------------+------+---------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n|age|       workclass|fnlwgt|education|education-num|    marital-status|       occupation| relationship| race|   sex|capital-gain|capital-loss|hours-per-week|native-country|income|\n+---+----------------+------+---------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n| 39|       State-gov| 77516|Bachelors|           13|     Never-married|     Adm-clerical|Not-in-family|White|  Male|        2174|           0|            40| United-States| <=50K|\n| 50|Self-emp-not-inc| 83311|Bachelors|           13|Married-civ-spouse|  Exec-managerial|      Husband|White|  Male|           0|           0|            13| United-States| <=50K|\n| 38|         Private|215646|  HS-grad|            9|          Divorced|Handlers-cleaners|Not-in-family|White|  Male|           0|           0|            40| United-States| <=50K|\n| 53|         Private|234721|     11th|            7|Married-civ-spouse|Handlers-cleaners|      Husband|Black|  Male|           0|           0|            40| United-States| <=50K|\n| 28|         Private|338409|Bachelors|           13|Married-civ-spouse|   Prof-specialty|         Wife|Black|Female|           0|           0|            40|          Cuba| <=50K|\n+---+----------------+------+---------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\nonly showing top 5 rows\n\n+---+----------------+------+---------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n|age|       workclass|fnlwgt|education|education_num|    marital_status|       occupation| relationship| race|   sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n+---+----------------+------+---------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n| 39|       State-gov| 77516|Bachelors|           13|     Never-married|     Adm-clerical|Not-in-family|White|  Male|        2174|           0|            40| United-States| <=50K|\n| 50|Self-emp-not-inc| 83311|Bachelors|           13|Married-civ-spouse|  Exec-managerial|      Husband|White|  Male|           0|           0|            13| United-States| <=50K|\n| 38|         Private|215646|  HS-grad|            9|          Divorced|Handlers-cleaners|Not-in-family|White|  Male|           0|           0|            40| United-States| <=50K|\n| 53|         Private|234721|     11th|            7|Married-civ-spouse|Handlers-cleaners|      Husband|Black|  Male|           0|           0|            40| United-States| <=50K|\n| 28|         Private|338409|Bachelors|           13|Married-civ-spouse|   Prof-specialty|         Wife|Black|Female|           0|           0|            40|          Cuba| <=50K|\n+---+----------------+------+---------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\nonly showing top 5 rows"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": "# (PART 1) Write and READ to SQL Table\r\n- Write dataframe to SQL table to SQL Master\r\n- Read SQL Table to Spark dataframe",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "#Write from Spark to SQL table using MSSQL Spark Connector\r\nprint(\"Use MSSQL connector to write to master SQL instance \")\r\n\r\nservername = \"jdbc:sqlserver://master-0.master-svc\"\r\ndbname = \"MyTestDatabase\"\r\nurl = servername + \";\" + \"databaseName=\" + dbname + \";\"\r\n\r\ndbtable = \"AdultCensus_test\"\r\nuser = \"*****\"\r\npassword = \"*****\" # Please specify password here\r\n\r\n#com.microsoft.sqlserver.jdbc.spark\r\n\r\ntry:\r\n  df.write \\\r\n    .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\r\n    .mode(\"overwrite\") \\\r\n    .option(\"url\", url) \\\r\n    .option(\"dbtable\", dbtable) \\\r\n    .option(\"user\", user) \\\r\n    .option(\"password\", password) \\\r\n    .save()\r\nexcept ValueError as error :\r\n    print(\"MSSQL Connector write failed\", error)\r\n\r\nprint(\"MSSQL Connector write(overwrite) succeeded  \")\r\n\r\n\r\n",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Use MSSQL connector to write to master SQL instance \nMSSQL Connector write(overwrite) succeeded"
                }
            ],
            "execution_count": 5
        },
        {
            "cell_type": "code",
            "source": "#Use mode as append\r\ntry:\r\n  df.write \\\r\n    .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\r\n    .mode(\"append\") \\\r\n    .option(\"url\", url) \\\r\n    .option(\"dbtable\", dbtable) \\\r\n    .option(\"user\", user) \\\r\n    .option(\"password\", password) \\\r\n    .save()\r\nexcept ValueError as error :\r\n    print(\"MSSQL Connector write failed\", error)\r\n\r\nprint(\"MSSQL Connector write(append) succeeded  \")",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "MSSQL Connector write(append) succeeded"
                }
            ],
            "execution_count": 6
        },
        {
            "cell_type": "code",
            "source": "#Read from SQL table using MSSQ Connector\r\nprint(\"read data from SQL server table  \")\r\njdbcDF = spark.read \\\r\n        .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\r\n        .option(\"url\", url) \\\r\n        .option(\"dbtable\", dbtable) \\\r\n        .option(\"user\", user) \\\r\n        .option(\"password\", password).load()\r\n\r\njdbcDF.show(5)",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "read data from SQL server table  \n+---+----------------+------+---------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n|age|       workclass|fnlwgt|education|education_num|    marital_status|       occupation| relationship| race|   sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n+---+----------------+------+---------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n| 39|       State-gov| 77516|Bachelors|           13|     Never-married|     Adm-clerical|Not-in-family|White|  Male|        2174|           0|            40| United-States| <=50K|\n| 50|Self-emp-not-inc| 83311|Bachelors|           13|Married-civ-spouse|  Exec-managerial|      Husband|White|  Male|           0|           0|            13| United-States| <=50K|\n| 38|         Private|215646|  HS-grad|            9|          Divorced|Handlers-cleaners|Not-in-family|White|  Male|           0|           0|            40| United-States| <=50K|\n| 53|         Private|234721|     11th|            7|Married-civ-spouse|Handlers-cleaners|      Husband|Black|  Male|           0|           0|            40| United-States| <=50K|\n| 28|         Private|338409|Bachelors|           13|Married-civ-spouse|   Prof-specialty|         Wife|Black|Female|           0|           0|            40|          Cuba| <=50K|\n+---+----------------+------+---------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\nonly showing top 5 rows"
                }
            ],
            "execution_count": 7
        },
        {
            "cell_type": "markdown",
            "source": "# (PART 2) Write and READ to Data Pool external Tables in Big Data Cluster\r\n- Write dataframe to SQL external table in Data Pools in Big Data Cluste\r\n- Read SQL external Table to Spark dataframe",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "#Write from Spark to SQL table using MSSQL Spark Connector\r\nprint(\"Use MSSQL connector to write to master SQL instance \")\r\n\r\ndatapool_table = \"AdultCensus_DataPoolTable\"\r\ndatasource_name = \"test_data_src\"\r\n\r\n\r\ntry:\r\n  df.write \\\r\n    .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\r\n    .mode(\"overwrite\") \\\r\n    .option(\"url\", url) \\\r\n    .option(\"dbtable\", datapool_table) \\\r\n    .option(\"user\", user) \\\r\n    .option(\"password\", password) \\\r\n    .option(\"dataPoolDataSource\",datasource_name)\\\r\n    .save()\r\nexcept ValueError as error :\r\n    print(\"MSSQL Connector write failed\", error)\r\n\r\nprint(\"MSSQL Connector write(overwrite) to data pool external table succeeded\")\r\n",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Use MSSQL connector to write to master SQL instance \nMSSQL Connector write(overwrite) to data pool external table succeeded"
                }
            ],
            "execution_count": 8
        },
        {
            "cell_type": "code",
            "source": "try:\r\n  df.write \\\r\n    .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\r\n    .mode(\"append\") \\\r\n    .option(\"url\", url) \\\r\n    .option(\"dbtable\", datapool_table) \\\r\n    .option(\"user\", user) \\\r\n    .option(\"password\", password) \\\r\n    .option(\"dataPoolDataSource\",datasource_name)\\\r\n    .save()\r\nexcept ValueError as error :\r\n    print(\"MSSQL Connector write failed\", error)\r\n\r\nprint(\"MSSQL Connector write(append) to data pool external table succeeded\")",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "MSSQL Connector write(append) to data pool external table succeeded"
                }
            ],
            "execution_count": 9
        },
        {
            "cell_type": "code",
            "source": "#Read from SQL table using MSSQ Connector\r\nprint(\"read data from SQL server table  \")\r\njdbcDF = spark.read \\\r\n        .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\r\n        .option(\"url\", url) \\\r\n        .option(\"dbtable\", datapool_table) \\\r\n        .option(\"user\", user) \\\r\n        .option(\"password\", password)\\\r\n        .load()\r\n\r\njdbcDF.show(5)\r\n\r\nprint(\"MSSQL Connector read from data pool external table succeeded\")",
            "metadata": {},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "read data from SQL server table  \n+---+----------------+------+----------+-------------+------------------+---------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n|age|       workclass|fnlwgt| education|education_num|    marital_status|     occupation| relationship| race|   sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n+---+----------------+------+----------+-------------+------------------+---------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n| 46|Self-emp-not-inc|277946|Assoc-acdm|           12|         Separated|   Craft-repair|Not-in-family|White|  Male|           0|           0|            40| United-States| <=50K|\n| 38|         Private| 91039| Bachelors|           13|Married-civ-spouse|          Sales|      Husband|White|  Male|       15024|           0|            60| United-States|  >50K|\n| 18|         Private|156764|      11th|            7|     Never-married|  Other-service|    Own-child|White|  Male|           0|           0|            40| United-States| <=50K|\n| 34|         Private|136721|   HS-grad|            9|          Divorced|Exec-managerial|Not-in-family|White|Female|           0|           0|            40| United-States| <=50K|\n| 39|       State-gov| 77516| Bachelors|           13|     Never-married|   Adm-clerical|Not-in-family|White|  Male|        2174|           0|            40| United-States| <=50K|\n+---+----------------+------+----------+-------------+------------------+---------------+-------------+-----+------+------------+------------+--------------+--------------+------+\nonly showing top 5 rows\n\nMSSQL Connector read from data pool external table succeeded"
                }
            ],
            "execution_count": 10
        }
    ]
}